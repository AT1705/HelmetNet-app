"""
AI Helmet Detection System (CSC738)
OPTIMIZED: Live Inference + Frame Skipping + Modern Safety Theme UI

UPDATED:
- Reliable WebRTC on hotspots using Twilio Network Traversal (TURN) tokens
- Use Streamlit Secrets (st.secrets) instead of os.environ
- Fix model_path input + loading
"""

import streamlit as st
from ultralytics import YOLO
import cv2
import numpy as np
from pathlib import Path
import tempfile
import time
from streamlit_webrtc import VideoTransformerBase, webrtc_streamer, WebRtcMode, RTCConfiguration

# NEW: Twilio client for TURN credentials (ephemeral)
from twilio.rest import Client

# ============================================================
# PAGE CONFIG
# ============================================================
st.set_page_config(
Â    page_title="AI Helmet Detection",
Â    page_icon="ğŸ›µ",
Â    layout="wide",
Â    initial_sidebar_state="expanded"
)

# ============================================================
# TWILIO TURN (Network Traversal Token -> ICE servers)
# ============================================================
@st.cache_resource
def get_twilio_ice_servers():
Â    """
Â    Gets ICE servers (STUN/TURN) from Twilio Network Traversal Service.
Â    This is the most reliable method for restrictive networks (hotspots).
Â    """
Â    try:
Â        account_sid = st.secrets["TWILIO_ACCOUNT_SID"]
Â        auth_token = st.secrets["TWILIO_AUTH_TOKEN"]
Â        client = Client(account_sid, auth_token)

Â        token = client.tokens.create()  # returns ephemeral TURN creds
Â        ice_servers = token.ice_servers

Â        # Safety: ensure list exists
Â        if not ice_servers:
Â            # fallback to STUN only
Â            return [{"urls": ["stun:stun.l.google.com:19302"]}]

Â        return ice_servers
Â    except Exception as e:
Â        # If Twilio fails, fallback to STUN only (may fail on hotspots)
Â        st.sidebar.error(f"TURN setup error: {e}")
Â        return [{"urls": ["stun:stun.l.google.com:19302"]}]


ICE_SERVERS = get_twilio_ice_servers()
RTC_CONFIGURATION = RTCConfiguration({"iceServers": ICE_SERVERS})

# ============================================================
# SAFETY THEME CSS
# ============================================================
st.markdown("""
<style>

&nbsp;   .block-container { padding-top: 1.5rem !important; }

&nbsp;   .main-header {

&nbsp;       font-size: 2.5rem; font-weight: 800; color: var(--text-color);

&nbsp;       text-align: center; text-shadow: 2px 2px 4px rgba(0,0,0,0.1);

&nbsp;   }

&nbsp;   .sub-header {

&nbsp;       text-align: center; font-size: 1.1rem; color: var(--text-color);

&nbsp;       opacity: 0.8; font-weight: 500; margin-bottom: 1.5rem;

&nbsp;   }

&nbsp;   h2 {

&nbsp;       color: var(--text-color) !important; font-weight: 700 !important;

&nbsp;       border-bottom: 3px solid #FFD700; padding-bottom: 0.5rem;

&nbsp;   }

&nbsp;   .stTabs \[data-baseweb="tab-list"] {

&nbsp;       background: var(--secondary-background-color); padding: 0.5rem;

&nbsp;       border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);

&nbsp;   }

&nbsp;   .stTabs \[data-baseweb="tab"] {

&nbsp;       height: 50px; border-radius: 8px; color: var(--text-color);

&nbsp;       font-weight: 600; padding: 0 1.5rem;

&nbsp;   }

&nbsp;   .stTabs \[aria-selected="true"] {

&nbsp;       background: #FFD700 !important; color: #1E3A8A !important;

&nbsp;   }

&nbsp;   .alert-danger {

&nbsp;       background: linear-gradient(135deg, #EF4444 0%, #DC2626 100%);

&nbsp;       color: white; padding: 20px; border-radius: 12px;

&nbsp;       text-align: center; font-size: 1.3rem; font-weight: 700;

&nbsp;       animation: pulse 2s infinite; margin: 20px 0;

&nbsp;       box-shadow: 0 4px 6px rgba(239,68,68,0.3);

&nbsp;       border: 3px solid #FCA5A5;

&nbsp;   }

&nbsp;   .alert-success {

&nbsp;       background: linear-gradient(135deg, #22C55E 0%, #16A34A 100%);

&nbsp;       color: white; padding: 20px; border-radius: 12px;

&nbsp;       text-align: center; font-size: 1.3rem; font-weight: 700;

&nbsp;       margin: 20px 0; box-shadow: 0 4px 6px rgba(34,197,94,0.3);

&nbsp;       border: 3px solid #86EFAC;

&nbsp;   }

&nbsp;   @keyframes pulse {0%, 100% {opacity: 1; transform: scale(1);} 50% {opacity: 0.85; transform: scale(1.02);}}

&nbsp;   .stButton > button {

&nbsp;       background: linear-gradient(135deg, #FFD700 0%, #FFA500 100%);

&nbsp;       color: #1E3A8A; border: none; border-radius: 10px;

&nbsp;       padding: 0.6rem 2rem; font-weight: 700;

&nbsp;       box-shadow: 0 4px 6px rgba(0,0,0,0.1);

&nbsp;   }

&nbsp;   .stButton > button:hover {

&nbsp;       transform: translateY(-2px);

&nbsp;       box-shadow: 0 6px 12px rgba(0,0,0,0.15);

&nbsp;       color: #1E3A8A;

&nbsp;   }

&nbsp;   .stDownloadButton > button {

&nbsp;       background: linear-gradient(135deg, #1E3A8A 0%, #3B82F6 100%);

&nbsp;       color: white; border: none;

&nbsp;   }

&nbsp;   \[data-testid="stMetricValue"] {

&nbsp;       font-size: 1.8rem !important; font-weight: 700 !important; color: var(--text-color);

&nbsp;   }

&nbsp;   \[data-testid="metric-container"] {

&nbsp;       background: var(--secondary-background-color); padding: 1rem;

&nbsp;       border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05);

&nbsp;       border-left: 4px solid #FFD700;

&nbsp;   }

&nbsp;   \[data-testid="stFileUploader"] {

&nbsp;       background: var(--secondary-background-color); padding: 1.5rem;

&nbsp;       border-radius: 10px; border: 2px dashed #FFD700;

&nbsp;   }

&nbsp;   audio {display: none;}

&nbsp;   .info-box {

&nbsp;       background: rgba(59, 130, 246, 0.1); padding: 1rem;

&nbsp;       border-radius: 10px; border-left: 4px solid #1E3A8A;

&nbsp;       margin: 1rem 0; color: var(--text-color);

&nbsp;   }

""", unsafe_allow_html=True)

# ============================================================
# CONFIGURATION
# ============================================================
NO_HELMET_LABELS = ["no helmet", "no_helmet", "no-helmet"]
CONFIDENCE_THRESHOLD = 0.50
FRAME_SKIP = 3
DEFAULT_MODEL_PATH = "best.pt"

# ============================================================
# UTILS & LOGIC
# ============================================================
@st.cache_resource
def load_model(path):
Â    try:
Â        if Path(path).exists():
Â            model = YOLO(path)
Â            st.sidebar.success("âœ… Model loaded")
Â            return model
Â        st.sidebar.warning("âš ï¸ Model not found, using YOLOv8n")
Â        return YOLO("yolov8n.pt")
Â    except Exception as e:
Â        st.sidebar.error(f"Model load error: {e}")
Â        return None

def play_alarm():
Â    if 'last_alarm' not in st.session_state:
Â        st.session_state.last_alarm = 0
Â    if time.time() - st.session_state.last_alarm > 3:
Â        if Path("alert.mp3").exists():
Â            st.audio("alert.mp3", format="audio/mp3", autoplay=True)
Â        st.session_state.last_alarm = time.time()

def draw_boxes(frame, detections):
Â    img = frame.copy()
Â    for det in detections:
Â        x1, y1, x2, y2 = map(int, det['bbox'])
Â        color = (0, 0, 139) if det['class'] in NO_HELMET_LABELS else (0, 100, 0)
Â        label = f"{det['class']} {det['confidence']:.2f}"

Â        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
Â        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
Â        cv2.rectangle(img, (x1, y1 - 20), (x1 + w, y1), color, -1)
Â        cv2.putText(img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
Â    return img

def detect_frame(frame, model, conf_threshold):
Â    results = model.predict(frame, conf=conf_threshold, imgsz=640, verbose=False, device='cpu')

Â    helmet_count = 0
Â    no_helmet_count = 0
Â    detections = []

Â    for box in results[0].boxes:
Â        cls_id = int(box.cls)
Â        cls_name = model.names[cls_id].lower()
Â        conf = float(box.conf)
Â        bbox = box.xyxy[0].cpu().numpy().tolist()

Â        detections.append({'class': cls_name, 'confidence': conf, 'bbox': bbox})

Â        if cls_name in NO_HELMET_LABELS:
Â            no_helmet_count += 1
Â        else:
Â            helmet_count += 1

Â    return detections, {
Â        'helmet_count': helmet_count,
Â        'no_helmet_count': no_helmet_count,
Â        'alert': no_helmet_count > 0
Â    }

# ============================================================
# WEBRTC CLASS
# ============================================================
class HelmetTransformer(VideoTransformerBase):
Â    def __init__(self):
Â        self.model = None
Â        self.conf = 0.25
Â        self.helmet = 0
Â        self.no_helmet = 0
Â        self.frame_cnt = 0
Â        self.last_dets = []
Â        self.alert = False

Â    def set_model(self, model, conf):
Â        self.model = model
Â        self.conf = conf

Â    def transform(self, frame):
Â        img = frame.to_ndarray(format="bgr24")
Â        if self.model is None:
Â            return img

Â        self.frame_cnt += 1

Â        if self.frame_cnt % FRAME_SKIP == 0:
Â            try:
Â                detections, stats = detect_frame(img, self.model, self.conf)
Â                self.last_dets = detections
Â                self.helmet = stats['helmet_count']
Â                self.no_helmet = stats['no_helmet_count']
Â                self.alert = stats['alert']
Â            except Exception:
Â                pass

Â        return draw_boxes(img, self.last_dets)

# ============================================================
# SIDEBAR
# ============================================================
with st.sidebar:
Â    st.markdown("### âš™ï¸ Configuration")
Â    st.markdown("---")

Â    st.markdown("**ğŸ¤– Model Settings**")
Â    model_path = st.text_input("Model Path", DEFAULT_MODEL_PATH)

Â    confidence_threshold = st.slider("ğŸ¯ Confidence", 0.1, 1.0, CONFIDENCE_THRESHOLD, 0.05)

Â    st.markdown("---")
Â    st.markdown("**ğŸŒ WebRTC / TURN Debug**")
Â    st.write("ICE servers loaded:", len(ICE_SERVERS))
Â    # Optional: show first server for sanity (not credentials)
Â    if len(ICE_SERVERS) > 0 and "urls" in ICE_SERVERS[0]:
Â        st.write("First ICE urls:", ICE_SERVERS[0]["urls"])

Â    st.markdown("---")
Â    st.markdown("**ğŸ“Š Session Stats**")
Â    if 'total_detections' not in st.session_state:
Â        st.session_state.total_detections = 0
Â    st.metric("Total Detections", st.session_state.total_detections)

Â    st.markdown("---")

# ============================================================
# LOAD MODEL
# ============================================================
model = load_model(model_path)
if not model:
Â    st.sidebar.warning(f"âš ï¸ Could not load {model_path}, using default YOLOv8n")
Â    model = YOLO("yolov8n.pt")

# ============================================================
# MAIN APP UI
# ============================================================
st.markdown('<h1 class="main-header">ğŸ›µ HelmetNet </h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">AI Helmet Detection System</p>', unsafe_allow_html=True)

tab1, tab2, tab3 = st.tabs(["Image Detection", "Video Detection", "Real-Time Detection"])

# --- TAB 1: IMAGE DETECTION ---
with tab1:
Â    st.markdown("### ğŸ“¸ Upload an Image")

Â    col1, col2 = st.columns([2, 1])
Â    with col2:
Â        st.markdown(
Â            '<div class="info-box"><strong>ğŸ’¡ Tips:</strong><br>â€¢ Clear, well-lit images<br>â€¢ JPG, PNG, BMP</div>',
Â            unsafe_allow_html=True
Â        )

Â    with col1:
Â        img_file = st.file_uploader(
Â            "Choose image",
Â            ["jpg", "jpeg", "png", "bmp"],
Â            key="img",
Â            label_visibility="collapsed"
Â        )

Â    if img_file:
Â        file_bytes = np.asarray(bytearray(img_file.read()), dtype=np.uint8)
Â        frame = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

Â        with st.spinner("ğŸ” Analyzing..."):
Â            dets, stats = detect_frame(frame, model, confidence_threshold)
Â            annotated = draw_boxes(frame, dets)
Â            st.session_state.total_detections += len(dets)

Â        annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)

Â        c1, c2 = st.columns(2, gap="large")
Â        with c1:
Â            st.markdown("**ğŸ“· Original**")
Â            st.image(img_file, use_container_width=True)
Â        with c2:
Â            st.markdown("**ğŸ¯ Result**")
Â            st.image(annotated_rgb, use_container_width=True)

Â        if stats['alert']:
Â            st.markdown('<div class="alert-danger">âš ï¸ NO HELMET DETECTED!</div>', unsafe_allow_html=True)
Â            play_alarm()
Â        else:
Â            st.markdown('<div class="alert-success">âœ… All Safe!</div>', unsafe_allow_html=True)

Â        st.markdown("### ğŸ“Š Summary")
Â        m1, m2, m3 = st.columns(3)
Â        m1.metric("ğŸŸ¢ Helmets", stats['helmet_count'])
Â        m2.metric("ğŸ”´ No Helmets", stats['no_helmet_count'])
Â        m3.metric("ğŸ“ Total Objects", len(dets))

Â        temp_img = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
Â        cv2.imwrite(temp_img.name, annotated)
Â        with open(temp_img.name, 'rb') as f:
Â            st.download_button("ğŸ“¥ Download Result", f, f"result_{img_file.name}", "image/jpeg")

# --- TAB 2: VIDEO DETECTION ---
with tab2:
Â    st.markdown("### ğŸ¥ Upload a Video")

Â    col1, col2 = st.columns([2, 1])
Â    with col2:
Â        st.markdown(
Â            '<div class="info-box"><strong>ğŸ’¡ Fast Mode:</strong><br>â€¢ Optimized frame skipping<br>â€¢ Live inference preview<br>â€¢ MP4, AVI, MOV</div>',
Â            unsafe_allow_html=True
Â        )

Â    with col1:
Â        vid_file = st.file_uploader(
Â            "Choose video",
Â            ["mp4", "avi", "mov", "mkv"],
Â            key="vid",
Â            label_visibility="collapsed"
Â        )

Â    if vid_file:
Â        st.markdown("### ğŸ¬ Processing")
Â        if st.button("â–¶ï¸ Start Live Inference", type="primary"):
Â            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
Â            tfile.write(vid_file.read())

Â            cap = cv2.VideoCapture(tfile.name)
Â            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
Â            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
Â            fps = int(cap.get(cv2.CAP_PROP_FPS))
Â            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

Â            outfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
Â            out = cv2.VideoWriter(outfile.name, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

Â            st_frame = st.empty()
Â            st_metrics = st.empty()
Â            st_progress = st.progress(0)

Â            frame_count = 0
Â            cached_detections = []
Â            current_stats = {'helmet_count': 0, 'no_helmet_count': 0, 'alert': False}

Â            while cap.isOpened():
Â                ret, frame = cap.read()
Â                if not ret:
Â                    break

Â                frame_count += 1

Â                if frame_count % FRAME_SKIP == 0 or frame_count == 1:
Â                    cached_detections, current_stats = detect_frame(frame, model, confidence_threshold)

Â                annotated = draw_boxes(frame, cached_detections)
Â                out.write(annotated)

Â                if current_stats['alert']:
Â                    play_alarm()

Â                st_frame.image(
Â                    cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB),
Â                    caption=f"Processing Frame {frame_count}/{total_frames}",
Â                    use_container_width=True
Â                )

Â                with st_metrics.container():
Â                    c1, c2, c3 = st.columns(3)
Â                    c1.metric("ğŸŸ¢ Helmets", current_stats['helmet_count'])
Â                    c2.metric("ğŸ”´ Violations", current_stats['no_helmet_count'])
Â                    c3.metric("â±ï¸ Progress", f"{int(frame_count/total_frames*100)}%")

Â                st_progress.progress(frame_count / total_frames)

Â            cap.release()
Â            out.release()

Â            st.success("âœ… Processing Complete!")
Â            st.session_state.total_detections += (current_stats['helmet_count'] + current_stats['no_helmet_count'])

Â            with open(outfile.name, 'rb') as f:
Â                st.download_button("ğŸ“¥ Download Result", f, "result.mp4", "video/mp4")

# --- TAB 3: REAL-TIME DETECTION (WEBRTC) ---
with tab3:
Â    st.markdown("### ğŸ“± Real-Time Live Detection")
Â    st.markdown("""
Â    <div class="info-box">
Â    <strong>ğŸ¥ Live Webcam:</strong><br>
Â    â€¢ Click "START" below<br>
Â    â€¢ Uses optimized frame skipping for smoother performance<br>
Â    â€¢ Works on mobile & desktop (TURN enabled for hotspots)
Â    </div>
Â    """, unsafe_allow_html=True)

Â    ctx = webrtc_streamer(
Â        key="helmet-live",
Â        mode=WebRtcMode.SENDRECV,
Â        rtc_configuration=RTC_CONFIGURATION,
Â        video_processor_factory=HelmetTransformer,
Â        async_processing=True,
Â    )

Â    if ctx.video_processor:
Â        ctx.video_processor.set_model(model, confidence_threshold)

Â        st.markdown("### ğŸ“Š Live Stats")
Â        m1, m2 = st.columns(2)
Â        m1.metric("ğŸŸ¢ Helmets", ctx.video_processor.helmet)
Â        m2.metric("ğŸ”´ Violations", ctx.video_processor.no_helmet)

Â        if ctx.video_processor.alert:
Â            st.markdown('<div class="alert-danger">âš ï¸ NO HELMET DETECTED!</div>', unsafe_allow_html=True)
Â            play_alarm()
Â        else:
Â            st.markdown('<div class="alert-success">âœ… Area Secure</div>', unsafe_allow_html=True)

st.markdown("---")
st.caption("ğŸš€ HelmetNet App | Â© 2025")
